深度学习中张量的理解
----

<!-- TOC -->

- [标量-向量-矩阵-张量](#标量-向量-矩阵-张量)
- [张量](#张量)
- [小结](#小结)

<!-- /TOC -->
## 标量-向量-矩阵-张量
  
在深度学习中，在TensorFlow、PaddlePaddle等框架中经常提到tensor，tensor就是张量的意思。

张量是矩阵的扩展与延伸。

|标量|  向量| 矩阵| 3阶张量| n阶张量 |
|-|-|-|-|-|
|只有大小| 有大小和方向| 由行列两个向量组成| 由行列高三个向量组成| 由N个互相垂直的向量组成|   
||一维空间| 二维空间| 三维空间| N维空间|

## 张量

**Tensor的对象有三个属性：**

**（1）rank：number of dimensions**

**（2）shape: number of rows and columns**

**（3）type: data type of tensor's elements**

结合其属性就很好理解张量了，参考例子：

3 # a rank 0 tensor; this is a scalar with shape \[\]  
\[1. ,2., 3.\] # a rank 1 tensor; this is a vector with shape \[3\]  
\[\[1., 2., 3.\], \[4., 5., 6.\]\] # a rank 2 tensor; a matrix with shape \[2, 3\]  
\[\[\[1., 2., 3.\]\], \[\[7., 8., 9.\]\]\] # a rank 3 tensor with shape \[2, 1, 3\] 常说的张量就是3阶张量

张量的阶数有时候也称为维度，或者轴。譬如一个矩阵\[\[1,2\],\[3,4\]\]，是一个2阶张量，有两个维度或轴，沿着第0个轴（为了与python的计数方式一致）你看到的是\[1,2\]，\[3,4\]两个向量，沿着第1个轴你看到的是\[1,3\]，\[2,4\]两个向量。

下面的代码可以帮助理解张量tensor“沿着某个轴”是什么意思

```python
import numpy as np
a = np.array([[1,2],[3,4]]) 
sum0 = np.sum(a, axis=0) 
sum1 = np.sum(a, axis=1)
print(a)
print(sum0) 
print(sum1) 
```


## 小结

在深度学习中，**Tensor实际上就是一个多维数组（multidimensional array），其目的** 是**能够创造更高维度的矩阵、向量** 。

在计算机视觉中，彩色图片就是用3阶张量描述的。黑白图片可以用矩阵描述，加上高度维度描述RGB后就可以描述彩色图片了。




----
<font size=2 color='grey'>本文收藏来自互联网，仅用于学习研究，著作权归原作者所有，如有侵权请联系删除</font>

markdown [@TsingChan](http://www.9ong.com/) 

> 引用格式为收藏注解，比如本句就是注解，非作者原文。
