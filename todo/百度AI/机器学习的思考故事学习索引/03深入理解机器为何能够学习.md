
<!-- TOC -->

- [机器为何能够学习](#机器为何能够学习)
    - [术语概念](#术语概念)
    - [机器为何能学习](#机器为何能学习)
    - [重要权衡的四张面孔](#重要权衡的四张面孔)
    - [过拟合的成因](#过拟合的成因)

<!-- /TOC -->

# 机器为何能够学习

## 术语概念

- 大数定律
- 基于概率的信任
- n次方多项式



## 机器为何能学习

- 大数定律

    三人成虎

    当试验次数足够多时，时间出现的频率接近于事件真实的发生概率

    价值可能会被高估或低估，但长期来看，价格回归价值。/马哲@客观/

    运气可能有的人多有的人少，但长期来看，运气大家都是一样，只要尝试的次数足够多，运气还是平衡的。/马哲@时间会证明的，主观能动/

    祸兮福所倚福兮祸所伏。

    你可以不成功，但你不能不成长，也许有人会阻碍你成功，但没有人会阻碍你成长  ---  杨澜

    相信大数定律，是金子总会发光，出来混总是要还的。

- 上帝掷骰子吗

    薛定谔定律

    爱因斯坦的确定论


    - 频率派
    - 贝叶斯派

- 机器学习是否可行

    机器学习，根据已知样本及标准，假设空间，并寻找假设空间中最好的一个假设。

    罐子里的小球就是真实的全部数据

    每一次抽出的10个小球就是抽样观察的数据，每次训练数据

    每次抽出小球都是一次有意义的数据训练

    模型也需要经过实际业务的检验。/马哲@时间是检验真理的唯一标准/

- 乐观欺骗

- 样本特征

    特征越多，模型能力越强

## 重要权衡的四张面孔

- 大明王朝的七张面孔

从多个角度反复理解一个事物，才能真正看透它（/马哲@全面、联系、发展的看待事物/）

- 面孔1：直观的感觉-细致与置信

    数据切分，每个格子足够细致，每个格子的数据量足够大，保证置信与细致准确。

    大数定律理解数据分析技巧：一方面保证分类中的数据量（够置信、学到），一方面数据足够细分类（够细致、学好）

- 面孔2：理论推测

    M太小 欠拟合

    M太大 过拟合

    Ein ≈ Eout   

    Ein ≈ 0

    Ein：模型对于训练集拟合度（个人理解）

    Eout：模型对于测试集拟合度（个人理解）

    

- 面孔3：实例验证

    1、5、10、25次方多项式验证从欠拟合到过拟合

    过拟合实际上是模型多出了更多的伪规律

    当简单模型一开始对于训练集和测试集的拟合度是不高的，误差比较大，随着深入的学习，模型越来越复杂，模型对于两个数据集的拟合度越来越高，即越趋近于0，当模型过大出现过拟合，模型对训练集的拟合度是高的，但对于测试集的拟合度是低的。

    所以当你发现训练集的拟合度高时，而测试集的拟合度低时，就是模型能力过强，过拟合了，捕捉了太多细节，导致这个现象。

    /马哲@物极必反，事物的主要矛盾与次要矛盾，矛盾的主要方面与次要方面/    


- 面孔4：深入理解 bias 和 variance

    偏差与方差：https://www.jianshu.com/p/e5c2af344327

    |低偏差+低方差|低偏差+高方差|
    -|-|-
    |高偏差+低方差|高偏差+高方差|

    variance：方差

    bias：偏差

    方差决定模型的假设空间大小，方差越小，假设空间范围越小，越接近拟合

    偏差决定真实数据规律是否在假设空间范围内，偏差小，越容易在假设空间内，拟合度越高，即测试集拟合度也高





## 过拟合的成因

- 噪音


    - stochastic noise

        模型不复杂，但存在不少噪音

        模型在训练数据中学习时，可能学到噪音，导致样本数据学习的不错，也就是拟合度很高，但很大概率学习到的不是真实的规律。

    - deterministic noise

        模型很复杂（规律复杂），但训练数据太少，样本数量与需要学习的规律复杂度不匹配


- 过拟合原因

    - 1、S noise太大

        数据中随机误差过多

    - 2、D noise太大

        样本数量太小，和需要学习的规律复杂度不匹配

    - 3、模型复杂度太大：特别能想象的模型

    1+2 、 1+3的时候容易产生过拟合

- 防控方法

    - 1、更准确的数据资料，减少S noise：数据修正或数据清洗
    - 2、更多样本：收集更多的样本
    - 3、控制模型的复杂度（降低复杂度）：优化模型
        - 正则化
        - 校验：故意留一部分样本，模拟出Eout的衡量




----
视频：https://aistudio.baidu.com/aistudio/education/lessonvideo/283258











